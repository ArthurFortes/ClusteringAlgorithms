{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coclustering.paco import PaCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'C:/Users/forte/OneDrive/ml-100k/folds/1/train.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch::  0  | Entropy::  0.951613042947\n",
      "Epoch::  1  | Entropy::  0.951494614474\n",
      "Epoch::  2  | Entropy::  0.951443127297\n",
      "Epoch::  3  | Entropy::  0.951361871346\n",
      "Epoch::  4  | Entropy::  0.951140266116\n",
      "Epoch::  5  | Entropy::  0.951126878172\n",
      "Epoch::  6  | Entropy::  0.950469362281\n",
      "Epoch::  7  | Entropy::  0.950046400087\n",
      "Epoch::  8  | Entropy::  0.949969587808\n",
      "Epoch::  9  | Entropy::  0.947810364651\n",
      "Epoch::  10  | Entropy::  0.947717252743\n",
      "Epoch::  11  | Entropy::  0.947745452072\n",
      "Epoch::  12  | Entropy::  0.946907953884\n",
      "Epoch::  13  | Entropy::  0.946184606345\n",
      "Epoch::  14  | Entropy::  0.946032415065\n",
      "Epoch::  15  | Entropy::  0.94570934641\n",
      "Epoch::  16  | Entropy::  0.945377118836\n",
      "Epoch::  17  | Entropy::  0.945367583302\n",
      "Epoch::  18  | Entropy::  0.944714307734\n",
      "Final entropy:: 0.944714307734\n",
      "K rows::  9 and L columns::  42\n",
      "Number of bi-groups::  378\n",
      "Number of bi-groups needing recommendations::  333\n"
     ]
    }
   ],
   "source": [
    "pa = PaCo(df, 10, 60)\n",
    "pa.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 28, 50, 56, 64, 96, 97, 168, 195, 196, 215, 318, 423] \n",
      "\n",
      "[28, 50, 89, 96, 97, 172, 181, 196, 210, 215, 234]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "users = ()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "uns_items = defaultdict()\n",
    "\n",
    "for n, k in enumerate(pa.list_row):\n",
    "    cols = pa.density[n].argsort()\n",
    "    cols = np.array(cols).ravel()[::-1]\n",
    "    \n",
    "    for u_idx in k:\n",
    "        user = pa.training_set['map_user'][u_idx]\n",
    "        unseen_items = set()\n",
    "        for l in cols:\n",
    "            if pa.density[n, l] != 0 and pa.density[n, l] != 1:\n",
    "                for i_idx in pa.list_col[l]:\n",
    "                    item = pa.training_set['map_item'][i_idx]\n",
    "                    if pa.training_set['feedback'][user].get(item, -1) == -1:\n",
    "                        unseen_items.add(item)\n",
    "            \n",
    "            if len(unseen_items) > 10:   \n",
    "                break\n",
    "                \n",
    "        uns_items[user] =  unseen_items\n",
    "\n",
    "print(sorted(uns_items[5]), '\\n')\n",
    "\n",
    "print(sorted(uns_items[6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n"
     ]
    }
   ],
   "source": [
    "# count_bi_groups = 0\n",
    "# for k in range(len(pa.list_row)):\n",
    "#    for l in range(len(pa.list_col)): \n",
    "#         if pa.density[k, l] != 0 and pa.density[k, l] != 1:\n",
    "#             # print(len(pa.list_row[k]), len(pa.list_col[l]), pa.density[k,l])\n",
    "#             count_bi_groups+= 1\n",
    "\n",
    "out = 'C:/Users/forte/OneDrive/ml-100k/folds/1/train_'\n",
    "list_file = []\n",
    "users = set()\n",
    "\n",
    "for n, k in enumerate(pa.list_row):\n",
    "    new_out = out + str(n) + '.dat'\n",
    "    list_file.append(new_out)\n",
    "    ls_feedback = []\n",
    "    \n",
    "    for u in k:\n",
    "        user = pa.training_set['map_user'][u]\n",
    "        users.add(user)\n",
    "        for item in pa.training_set['feedback'][user]:\n",
    "            ls_feedback.append((user, item, pa.training_set['feedback'][user][item]))\n",
    "    \n",
    "    ls_feedback = sorted(ls_feedback, key=lambda x: x[0])\n",
    "    \n",
    "    with open(new_out, 'w') as wf:\n",
    "        for sample in ls_feedback:\n",
    "            wf.write(\"%d\\t%d\\t%f\\n\" % (sample[0], sample[1], sample[2]))\n",
    "            \n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.run_mml import RunMyMediaLite\n",
    "from itertools import chain\n",
    "\n",
    "predict = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_'\n",
    "filenames = []\n",
    "for n, ft in enumerate(list_file):\n",
    "    new_predict = predict + str(n) + '.dat'\n",
    "    filenames.append(new_predict)\n",
    "    RunMyMediaLite(ft, prediction_file=new_predict).item_recommendation('BPRMF')\n",
    "\n",
    "RunMyMediaLite(df, prediction_file='C:/Users/forte/OneDrive/ml-100k/folds/1/p_bprmf.dat').item_recommendation('BPRMF')\n",
    "\n",
    "with open('C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final.dat', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prec@1': 0.27342, 'Recall@1': 0.04039, 'NDCG@1': 0.27342, 'MAP@1': 0.04039, 'Prec@3': 0.21786, 'Recall@3': 0.08989, 'NDCG@3': 0.43581999999999999, 'MAP@3': 0.07243, 'Prec@5': 0.1902, 'Recall@5': 0.13126, 'NDCG@5': 0.46072000000000002, 'MAP@5': 0.09213, 'Prec@10': 0.15621, 'Recall@10': 0.20209, 'NDCG@10': 0.48119000000000001, 'MAP@10': 0.12208, 'MAP': 0.12208}\n",
      "{'Prec@1': 0.31046, 'Recall@1': 0.0421, 'NDCG@1': 0.31046000000000001, 'MAP@1': 0.0421, 'Prec@3': 0.26761, 'Recall@3': 0.1006, 'NDCG@3': 0.49791000000000002, 'MAP@3': 0.08096, 'Prec@5': 0.23638, 'Recall@5': 0.14353, 'NDCG@5': 0.51932999999999996, 'MAP@5': 0.10492, 'Prec@10': 0.1902, 'Recall@10': 0.22756, 'NDCG@10': 0.52078000000000002, 'MAP@10': 0.14554, 'MAP': 0.14554}\n"
     ]
    }
   ],
   "source": [
    "from caserec.evaluation.item_recommendation import ItemRecommendationEvaluation\n",
    "\n",
    "\n",
    "result1 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final.dat'\n",
    "result2 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/p_bprmf.dat'\n",
    "test = 'C:/Users/forte/OneDrive/ml-100k/folds/1/test.dat'\n",
    "\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result1, test))\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result2, test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
