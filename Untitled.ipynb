{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coclustering.paco import PaCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'C:/Users/forte/OneDrive/ml-100k/folds/1/train.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch::  0  | Entropy::  0.948474083199\n",
      "Epoch::  1  | Entropy::  0.95305008524\n",
      "Epoch::  2  | Entropy::  0.950634627119\n",
      "Epoch::  3  | Entropy::  0.949367540312\n",
      "Epoch::  4  | Entropy::  0.948847109842\n",
      "Epoch::  5  | Entropy::  0.949128008123\n",
      "Epoch::  6  | Entropy::  0.948708021259\n",
      "Epoch::  7  | Entropy::  0.948005936183\n",
      "Epoch::  8  | Entropy::  0.947705606853\n",
      "Epoch::  9  | Entropy::  0.94804926328\n",
      "Epoch::  10  | Entropy::  0.946616140114\n",
      "Epoch::  11  | Entropy::  0.94629607752\n",
      "Epoch::  12  | Entropy::  0.946015648399\n",
      "Epoch::  13  | Entropy::  0.945884916879\n",
      "Epoch::  14  | Entropy::  0.944730529852\n",
      "Epoch::  15  | Entropy::  0.944120173111\n",
      "Epoch::  16  | Entropy::  0.943575474434\n",
      "Epoch::  17  | Entropy::  0.944177717858\n",
      "Epoch::  18  | Entropy::  0.943723881713\n",
      "Epoch::  19  | Entropy::  0.943816091312\n",
      "Epoch::  20  | Entropy::  0.940199286381\n",
      "Epoch::  21  | Entropy::  0.941941623916\n",
      "Epoch::  22  | Entropy::  0.940340017735\n",
      "Epoch::  23  | Entropy::  0.94028657619\n",
      "Epoch::  24  | Entropy::  0.93629933885\n",
      "Epoch::  25  | Entropy::  0.935550728648\n",
      "Epoch::  26  | Entropy::  0.93167578881\n",
      "Final entropy:: 0.93167578881\n",
      "K rows::  9 and L columns::  19\n",
      "Number of bi-groups::  171\n",
      "Number of bi-groups needing recommendations::  155\n"
     ]
    }
   ],
   "source": [
    "pa = PaCo(df, 15, 40)\n",
    "pa.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "users = ()\n",
    "\n",
    "si_matrix = np.float32(squareform(pdist(pa.training_set['matrix'].T, 'cosine')))\n",
    "su_matrix = np.float32(squareform(pdist(pa.training_set['matrix'], 'cosine')))\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "uns_items = defaultdict()\n",
    "\n",
    "for n, k in enumerate(pa.list_row):\n",
    "    cols = pa.density[n].argsort()\n",
    "    cols = np.array(cols).ravel()[::-1]\n",
    "    \n",
    "    for u_idx in k:\n",
    "        user = pa.training_set['map_user'][u_idx]\n",
    "        unseen_items = set()\n",
    "        for l in cols:\n",
    "            if pa.density[n, l] != 0 and pa.density[n, l] != 1:\n",
    "                for i_idx in pa.list_col[l]:\n",
    "                    item = pa.training_set['map_item'][i_idx]\n",
    "                    if pa.training_set['feedback'][user].get(item, -1) == -1:\n",
    "                        unseen_items.add(item)\n",
    "            \n",
    "            if len(unseen_items) > 75:   \n",
    "                break\n",
    "                \n",
    "        uns_items[user] =  unseen_items\n",
    "\n",
    "        \n",
    "def predict_per_item(user):\n",
    "    rank = []\n",
    "    for item_j in uns_items[user]:    \n",
    "        score = 0\n",
    "        ji = pa.training_set['mi'][item_j]\n",
    "        for item_i in pa.training_set['feedback'][user]:\n",
    "            jj = pa.training_set['mi'][item_i]\n",
    "            score += si_matrix[ji, jj]\n",
    "        rank.append((user, item_j, score))\n",
    "\n",
    "    return sorted(rank, key=lambda x: x[2])[:10]\n",
    "\n",
    "def predict_per_user(user):\n",
    "    u = pa.training_set['mu'][user]\n",
    "    rank = []\n",
    "    for item_j in uns_items[user]: \n",
    "        ji = pa.training_set['mi'][item_j]\n",
    "        users_ids = [pa.training_set['mu'][user_j] for user_j in pa.training_set['di'][item_j]]\n",
    "        sim_sum = sorted(np.take(su_matrix[u], users_ids), key=lambda x: x)\n",
    "        rank.append((user, item_j, sum(sim_sum[:30])))\n",
    "\n",
    "    return sorted(rank, key=lambda x: x[2])[:10]\n",
    "\n",
    "rank = []\n",
    "for user in pa.training_set['users']:\n",
    "    rank += predict_per_user(user)\n",
    "    \n",
    "with open('C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final_user.dat', 'w') as wf:\n",
    "    for sample in rank:\n",
    "        wf.write(\"%d\\t%d\\t%f\\n\" % (sample[0], sample[1], sample[2]))\n",
    "\n",
    "rank = []\n",
    "for user in pa.training_set['users']:\n",
    "    rank += predict_per_item(user)\n",
    "    \n",
    "with open('C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final_item.dat', 'w') as wf:\n",
    "    for sample in rank:\n",
    "        wf.write(\"%d\\t%d\\t%f\\n\" % (sample[0], sample[1], sample[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.run_mml import RunMyMediaLite\n",
    "RunMyMediaLite(df, prediction_file='C:/Users/forte/OneDrive/ml-100k/folds/1/p_bprmf.dat').item_recommendation('ITEMKNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prec@1': 0.00436, 'Recall@1': 0.00036, 'NDCG@1': 0.0043600000000000002, 'MAP@1': 0.00036, 'Prec@3': 0.00581, 'Recall@3': 0.00143, 'NDCG@3': 0.01461, 'MAP@3': 0.0008, 'Prec@5': 0.00632, 'Recall@5': 0.00245, 'NDCG@5': 0.019619999999999999, 'MAP@5': 0.00103, 'Prec@10': 0.00741, 'Recall@10': 0.00573, 'NDCG@10': 0.031379999999999998, 'MAP@10': 0.00151, 'MAP': 0.00151} \n",
      "\n",
      "{'Prec@1': 0.32898, 'Recall@1': 0.04364, 'NDCG@1': 0.32897999999999999, 'MAP@1': 0.04364, 'Prec@3': 0.27342, 'Recall@3': 0.10328, 'NDCG@3': 0.50548000000000004, 'MAP@3': 0.08419, 'Prec@5': 0.24684, 'Recall@5': 0.14673, 'NDCG@5': 0.52342999999999995, 'MAP@5': 0.11034, 'Prec@10': 0.19847, 'Recall@10': 0.2253, 'NDCG@10': 0.52708999999999995, 'MAP@10': 0.15132, 'MAP': 0.15132} \n",
      "\n",
      "{'Prec@1': 0.33333, 'Recall@1': 0.04246, 'NDCG@1': 0.33333000000000002, 'MAP@1': 0.04246, 'Prec@3': 0.26616, 'Recall@3': 0.09633, 'NDCG@3': 0.49215999999999999, 'MAP@3': 0.07977, 'Prec@5': 0.23028, 'Recall@5': 0.13524, 'NDCG@5': 0.51185999999999998, 'MAP@5': 0.10131, 'Prec@10': 0.17593, 'Recall@10': 0.20375, 'NDCG@10': 0.50863000000000003, 'MAP@10': 0.13326, 'MAP': 0.13326} \n",
      "\n",
      "{'Prec@1': 0.37473, 'Recall@1': 0.04844, 'NDCG@1': 0.37473000000000001, 'MAP@1': 0.04844, 'Prec@3': 0.30211, 'Recall@3': 0.11346, 'NDCG@3': 0.52581, 'MAP@3': 0.09605, 'Prec@5': 0.26187, 'Recall@5': 0.156, 'NDCG@5': 0.54427000000000003, 'MAP@5': 0.12275, 'Prec@10': 0.2012, 'Recall@10': 0.2331, 'NDCG@10': 0.55181000000000002, 'MAP@10': 0.16076, 'MAP': 0.16076} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from caserec.evaluation.item_recommendation import ItemRecommendationEvaluation\n",
    "\n",
    "result0 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final_user_sf.dat'\n",
    "result1 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final_user.dat'\n",
    "result2 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final_item.dat'\n",
    "result3 = 'C:/Users/forte/OneDrive/ml-100k/folds/1/p_bprmf.dat'\n",
    "test = 'C:/Users/forte/OneDrive/ml-100k/folds/1/test.dat'\n",
    "\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result0, test), '\\n')\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result1, test), '\\n')\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result2, test), '\\n')\n",
    "print(ItemRecommendationEvaluation().simple_evaluation(result3, test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_bi_groups = 0\n",
    "# for k in range(len(pa.list_row)):\n",
    "#    for l in range(len(pa.list_col)): \n",
    "#         if pa.density[k, l] != 0 and pa.density[k, l] != 1:\n",
    "#             # print(len(pa.list_row[k]), len(pa.list_col[l]), pa.density[k,l])\n",
    "#             count_bi_groups+= 1\n",
    "# \n",
    "# out = 'C:/Users/forte/OneDrive/ml-100k/folds/1/train_'\n",
    "# list_file = []\n",
    "# users = set()\n",
    "# \n",
    "# for n, k in enumerate(pa.list_row):\n",
    "#     new_out = out + str(n) + '.dat'\n",
    "#     list_file.append(new_out)\n",
    "#     ls_feedback = []\n",
    "#     \n",
    "#     for u in k:\n",
    "#         user = pa.training_set['map_user'][u]\n",
    "#         users.add(user)\n",
    "#         for item in pa.training_set['feedback'][user]:\n",
    "#             ls_feedback.append((user, item, pa.training_set['feedback'][user][item]))\n",
    "#     \n",
    "#     ls_feedback = sorted(ls_feedback, key=lambda x: x[0])\n",
    "#     \n",
    "#     with open(new_out, 'w') as wf:\n",
    "#         for sample in ls_feedback:\n",
    "#             wf.write(\"%d\\t%d\\t%f\\n\" % (sample[0], sample[1], sample[2]))\n",
    "#             \n",
    "# print(len(users))\n",
    "# \n",
    "# from clustering.run_mml import RunMyMediaLite\n",
    "# from itertools import chain\n",
    "# \n",
    "# predict = 'C:/Users/forte/OneDrive/ml-100k/folds/1/predict_'\n",
    "# filenames = []\n",
    "# for n, ft in enumerate(list_file):\n",
    "#     new_predict = predict + str(n) + '.dat'\n",
    "#     filenames.append(new_predict)\n",
    "#     RunMyMediaLite(ft, prediction_file=new_predict).item_recommendation('BPRMF')\n",
    "\n",
    "# RunMyMediaLite(df, prediction_file='C:/Users/forte/OneDrive/ml-100k/folds/1/p_bprmf.dat').item_recommendation('BPRMF')\n",
    "\n",
    "# with open('C:/Users/forte/OneDrive/ml-100k/folds/1/predict_final.dat', 'w') as outfile:\n",
    "#     for fname in filenames:\n",
    "#         with open(fname) as infile:\n",
    "#             for line in infile:\n",
    "#                 outfile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
